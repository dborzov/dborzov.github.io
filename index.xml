<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dmitry Peter Borzov</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Dmitry Peter Borzov</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    
    
    <lastBuildDate>Fri, 30 Jan 2015 08:36:54 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Understanding routing in Bittorrents: algorithms behind Kademlia DHT</title>
      <link>http://localhost:1313/posts/kademlia/</link>
      <pubDate>Fri, 30 Jan 2015 08:36:54 -0700</pubDate>
      
      <guid>http://localhost:1313/posts/kademlia/</guid>
      <description>

&lt;h1 id=&#34;routing-at-bittorrent-understanding-kademlia-dhts-distributed-hash-tables:fe965123d7524294753e9acd8d3c8d0a&#34;&gt;Routing at Bittorrent: understanding Kademlia DHTs (Distributed Hash Tables)&lt;/h1&gt;

&lt;p&gt;DHTs (Distributed Hash Tables) protocols are practical and useful tehcnologies and I am sure tat we are only beginning to untap their potential. Here is a good introduction to the core concepts behind the DHT Networks: &lt;a href=&#34;http://www.freedomlayer.org/articles/dht_intro.html&#34;&gt;www.freedomlayer.org/articles/dht_intro.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That article introduces Chord DHT protocol. In practice, many applications for untrusted networks use Kademlia, including the most succesful one to date: trackerless Bitttorrent file sharing.&lt;/p&gt;

&lt;p&gt;Here I am going to use NetVis, an open source network visualizer framework, to visualize in detail how Kademlia protocol operates.&lt;/p&gt;

&lt;p&gt;We will review a Kademlia-style DHT implementation from the IPFS source code as an example.
IPFS - Interplanetary File System is an amazing project that combines best and proved approaches behind git and gittorrent and you should &lt;a href=&#34;https://github.com/jbenet/ipfs&#34;&gt;totally learn about it&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While IPFS is an extensive project and combines many concepts, all we need to understand  for our purposes is that DHT there serves as  a routing purpose in the way similar to Bittorrent file swarm.&lt;/p&gt;

&lt;p&gt;That is, DHT network is used to fetch content stored at other nodes.  Content is identified by a unique hash. The DHT stores these content block hashes as keys and addresses of the nodes that have these content blocks as values.&lt;/p&gt;

&lt;p&gt;All that is implemented within the &lt;a href=&#34;https://godoc.org/github.com/jbenet/go-ipfs/routing&#34;&gt;routing/dht&lt;/a&gt; IPFS subpackage.&lt;/p&gt;

&lt;p&gt;DHT routing needs implement the following key commands:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PutValue&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GetValue&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Provide&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FindPeer&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dmitry Peter Borzov</title>
      <link>http://localhost:1313/home/home/</link>
      <pubDate>Fri, 23 Jan 2015 12:43:09 &#43;0500</pubDate>
      
      <guid>http://localhost:1313/home/home/</guid>
      <description>

&lt;h2 id=&#34;hi-i-am-dmitry-peter-borzov:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;Hi, I am Dmitry Peter Borzov&lt;/h2&gt;

&lt;p&gt;I specialize in development of web and data analysis applications. My experience includes working with javascript [d3, Angular, Ember, node], golang, python [pandas, scipy, django, flask] and C# among other technologies.&lt;/p&gt;

&lt;h2 id=&#34;open-source-projects:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;Open source projects&lt;/h2&gt;

&lt;p&gt;(also, see my &lt;a href=&#34;https://github.com/dborzov&#34;&gt;github account page&lt;/a&gt;)&lt;/p&gt;

&lt;h4 id=&#34;lsp-ls-shell-command-alternative-https-github-com-dborzov-lsp:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;&lt;a href=&#34;https://github.com/dborzov/lsp&#34;&gt;&lt;strong&gt;lsp&lt;/strong&gt; - &lt;code&gt;ls&lt;/code&gt; shell command alternative&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;ls&lt;/code&gt;  reimagined for modern times, with friendlier notations, built-in awareness of things like git repos and various dotfiles file datatypes.&lt;/p&gt;

&lt;h4 id=&#34;netvis-a-tool-to-visualize-and-understand-networks-https-github-com-dborzov-netvis:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;&lt;a href=&#34;https://github.com/dborzov/netvis&#34;&gt;&lt;strong&gt;NetVis&lt;/strong&gt; - a tool to visualize and understand networks&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Translate your network logs to a simple JSON-based NetVis format and visualize the network events and communication in detail. Check out the &lt;a href=&#34;http://www.borzov.ca/netvis/&#34;&gt;demo&lt;/a&gt;. Built in coordination with &lt;a href=&#34;http://ipfs.io/&#34;&gt;IPFS team&lt;/a&gt;, NetVis is an indispensable tool when designing and developing network functionality on any level.&lt;/p&gt;

&lt;h4 id=&#34;rusticsearch-is-a-simple-search-engine-server-https-github-com-dborzov-rusticsearch:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;&lt;a href=&#34;https://github.com/dborzov/rusticsearch&#34;&gt;&lt;strong&gt;RusticSearch&lt;/strong&gt; - is a simple search engine server&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;It uses in-memory suffix array to lookup index entries. RusticSearch is minimalistic in design and perfect when adding simple search functionality where &lt;a href=&#34;http://www.elasticsearch.org/&#34;&gt;fancier solutions&lt;/a&gt; can be an overkill.&lt;/p&gt;

&lt;h2 id=&#34;writings:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;Writings&lt;/h2&gt;

&lt;h4 id=&#34;jan-2015-routing-at-bittorrent-understanding-kademlia-dhts-distributed-hash-tables-posts-kademlia:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;&lt;a href=&#34;http://localhost:1313/posts/kademlia/&#34;&gt;&lt;em&gt;Jan 2015&lt;/em&gt; Routing at Bittorrent: understanding Kademlia DHTs (Distributed Hash Tables)&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Using NetVis framework to visualize algorithms behind Kademlia-styled DHT.&lt;/p&gt;

&lt;h4 id=&#34;dec-2013-predecessor-search-for-big-data-x-fast-tries-locality-of-reference-and-all-that-posts-xfast:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;&lt;a href=&#34;http://localhost:1313/posts/xfast/&#34;&gt;&lt;em&gt;Dec 2013&lt;/em&gt; Predecessor search for Big Data: x-fast tries, locality of reference and all that&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Introduction to X-fast trie-style data structures.&lt;/p&gt;

&lt;h2 id=&#34;research-papers:b9bcf8cb73ce4a081a635ad7c0acd9dd&#34;&gt;Research papers&lt;/h2&gt;

&lt;p&gt;Here is the list of academic peer-reviewed research papers I coauthored:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;M. S. Mashayekhi, J.-S. Bernier, D. Borzov, J.-L. Song, F. Zhou, &amp;ldquo;Two-dimensional Bose gases near resonance: universal three-body effects”, &lt;a href=&#34;http://prl.aps.org/abstract/PRL/v110/i14/e145301&#34;&gt;Phys. Rev. Lett. 110, 145301 (2013)&lt;/a&gt;, &lt;a href=&#34;http://arxiv.org/abs/1209.4929&#34;&gt;arxiv:1209.4929&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;D.Borzov, M.S.Mashayekhi, Sh.Zhang, J.Song, F.Zhou, &amp;ldquo;Nature of 3D Bose Gases near Resonance&amp;rdquo;, &lt;a href=&#34;http://pra.aps.org/abstract/PRA/v85/i2/e023620&#34;&gt;Phys.Rev. A 85, 023620 (2012)&lt;/a&gt;, &lt;a href=&#34;http://arxiv.org/abs/1110.2183&#34;&gt;arxiv:1110.2183&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;D.Borzov, &amp;ldquo;Optical vibrations of hydrogen in disordered palladium-gold alloys&amp;rdquo;, Physics of Extreme States of Matter (2009), &lt;a href=&#34;http://arxiv.org/abs/0901.1381&#34;&gt;arXiv:0901.1381v1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Predecessor search for Big Data: x-fast tries, locality of reference and all that</title>
      <link>http://localhost:1313/posts/xfast/</link>
      <pubDate>Sun, 01 Dec 2013 08:36:54 -0700</pubDate>
      
      <guid>http://localhost:1313/posts/xfast/</guid>
      <description>

&lt;h1 id=&#34;predecessor-search-for-big-data-x-fast-tries-locality-of-reference-and-all-that:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;Predecessor search for Big Data: x-fast tries, locality of reference and all that&lt;/h1&gt;

&lt;h3 id=&#34;abstract-an-intro-to-data-structures-with-locality-of-reference-type-features-we-review-x-fast-tries-in-somewhat-greater-detail-and-then-talk-some-about-similar-data-structures-where-they-shine-and-where-they-don-t:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;&lt;em&gt;Abstract:&lt;/em&gt; An intro to data structures with locality of reference-type features. We review x-fast tries in somewhat greater detail and then talk some about similar data structures, where they shine and where they don&amp;rsquo;t.&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s consider a set &lt;code&gt;{n}&lt;/code&gt; of &lt;code&gt;n&lt;/code&gt; integers within the range &lt;code&gt;0..M&lt;/code&gt;. We want to build a data structure that allows for performing the following operations efficiently:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Look up&lt;/strong&gt;: check if an integer &lt;code&gt;i&lt;/code&gt; is in &lt;code&gt;{n}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update&lt;/strong&gt;: Insert or delete an integer into &lt;code&gt;{n}&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is how commonly used data structures are holding up with these: or simply a sorted array, balanced binary search tree (whether it is AVL or red-black), hash table:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Lookup&lt;/th&gt;
&lt;th&gt;Update&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sorted Array&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(n)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Balanced binary tree&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hash Table&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The design of hash table is tailored for these two operations, however it performs much worse if we add the following operation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Find predecessor&lt;/strong&gt;  item: look up an integer &lt;code&gt;i&lt;/code&gt; and if it is not in the set, return the closest int within the set that is lower by value  (i.e, for 4 in {1,5,7} that would be 1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://localhost:1313/img/arrow.png&#34; alt=&#34;Img&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;Here is how we can implement Predecessor Search for these data structures:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Sorted Array&lt;/strong&gt; we search for the value using binary search and when if turns out that it is not within the set, we simply take the next left value from where it should have been.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Binary Tree&lt;/strong&gt; is similar to &lt;strong&gt;Sorted Array&lt;/strong&gt;: we traverse to the next item left from where the value should have been&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hash Table&lt;/strong&gt;: if the value &lt;code&gt;i&lt;/code&gt; is not within the set, the only option is to look up &lt;code&gt;i-1&lt;/code&gt; and continue looking up lower values until we stumble upon one within the set. The average distance between the two values is asymptotically &lt;code&gt;Ө(M/n)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Lookup&lt;/th&gt;
&lt;th&gt;Update&lt;/th&gt;
&lt;th&gt;Predeccessor&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sorted Array&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(n)&lt;/td&gt;
&lt;td&gt;O(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Balanced binary tree&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hash Table&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;O(M/n)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We see that the advantage of hash table evaporates before the predecessor operation. Is there a way to improve the data structure to fix this bad performance?&lt;/p&gt;

&lt;p&gt;One way to improve things that may come to mind at this point is to just store pointers to predecessor and successor elements for each of the the elements within &lt;code&gt;M&lt;/code&gt; right in the hash table.&lt;/p&gt;

&lt;p&gt;This would enable quick predecessor lookup, but would break the performance of the Update function.&lt;/p&gt;

&lt;p&gt;Indeed, adding a value for this Hash-Table with Predecessor Pointers means we need to update the predecessor pointer for all values from the new one to the closest larger one. Which, again, means O(M/n) operations.&lt;/p&gt;

&lt;p&gt;There is another drawback to this approach. Now we have to store not just &lt;code&gt;n&lt;/code&gt; set elements but all the &lt;code&gt;M&lt;/code&gt; possible values. Plus, each of the pointers is bound by &lt;code&gt;O(log(M))&lt;/code&gt; needed to store the value position. So the total size of the structure depends on M, which gets quite large.&lt;/p&gt;

&lt;p&gt;So we sum up the state of affairs with this table:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Lookup&lt;/th&gt;
&lt;th&gt;Update&lt;/th&gt;
&lt;th&gt;Predeccessor&lt;/th&gt;
&lt;th&gt;Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sorted Array&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(n)&lt;/td&gt;
&lt;td&gt;O(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Balanced binary tree&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hash Table&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(M/n)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hash-Table with Predecessor Pointers&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(M/n)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;reflection:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;Reflection&lt;/h4&gt;

&lt;p&gt;Let&amp;rsquo;s reflect on these results a little bit. We see that hash table is ideal when we look up exact values but breaks down when we start inquiring on operations where &lt;em&gt;locality&lt;/em&gt; of the value starts to matter.&lt;/p&gt;

&lt;p&gt;That makes sense. A proper hash function means a &lt;a href=&#34;http://en.wikipedia.org/wiki/Numerical_stability&#34;&gt;mathematically unstable&lt;/a&gt; one: even small increments change the hash completely which insures the values are spread homogeneously among the hash table buckets.&lt;/p&gt;

&lt;p&gt;At the same time we see that binary search tree-style data structures are quite resielent to &lt;em&gt;locality&lt;/em&gt; context class of problem. The search tree is based on the concept of proximity and contains the information about locality.&lt;/p&gt;

&lt;p&gt;X-fast trie is a data structure that combines the advantages of both search trees and hash tables.&lt;/p&gt;

&lt;h4 id=&#34;enter-x-fast-trie:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;Enter X-fast trie&lt;/h4&gt;

&lt;p&gt;Let&amp;rsquo;s build a bitwise search tree on top of all the M elements. All the M values are at the tree&amp;rsquo;s leaves (which makes this search tree a trie). We now mark all those tree nodes where there is an ancestor leave which is within &amp;lsquo;{n}&amp;rsquo; with black. Now let&amp;rsquo;s try out the following operations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Predecessor&lt;/strong&gt;: there is &lt;code&gt;log(M)&lt;/code&gt; nodes within the search tree that are parents to the leave corresponding to the value we look up. If a node is marked with black all the nodes above are black too. That means we have a sorted array of &lt;code&gt;log(M)&lt;/code&gt; values corresponding to the &lt;code&gt;i&lt;/code&gt; element. We use binary search to find the lowest black element and then traverse down the left side along the black nodes to get to the predecessor value. How much will it cost? Binary search among &lt;code&gt;log(M)&lt;/code&gt; values would be &lt;code&gt;Ө(log(log(M)))&lt;/code&gt;, traversing down to predecessor value: &lt;code&gt;Ө(1)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: is quite similar to the simple trie update case. For adding a value, ee traverse through all the parent nodes and &amp;ldquo;repaint&amp;rdquo; all of them black. For removing an item, we paint with white all the parent nodes for which no other children leaves are black. So &lt;code&gt;Ө(log(M))&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Storage of the color bits for the whole each node within the search tree can grow quite quickly: we get 2M-1 nodes for a binary trie with M leaves. That is where a hash table comes in, we store all the &amp;ldquo;black&amp;rdquo;-marked nodes within the hash table for each level. That means &lt;code&gt;n&lt;/code&gt; entries on the leave level, &lt;code&gt;n/2&lt;/code&gt; on the second lowest and so on for each of the &lt;code&gt;log(M)&lt;/code&gt; hash tables. So the space is  bound by &lt;code&gt;Ө(n log(M))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s sum it up by updating the table&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Lookup&lt;/th&gt;
&lt;th&gt;Update&lt;/th&gt;
&lt;th&gt;Predeccessor&lt;/th&gt;
&lt;th&gt;Size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sorted Array&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(n)&lt;/td&gt;
&lt;td&gt;O(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Balanced binary tree&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;Ө(log(n))&lt;/td&gt;
&lt;td&gt;O(log(n))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hash Table&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(M/n)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Hash-Table with Predecessor Pointers&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(1)&lt;/td&gt;
&lt;td&gt;Ө(M/n)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;X-fast trie&lt;/td&gt;
&lt;td&gt;O(1)&lt;/td&gt;
&lt;td&gt;O(log(M))&lt;/td&gt;
&lt;td&gt;O(log(log(M)))&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;toy-example:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;Toy example&lt;/h4&gt;

&lt;p&gt;The easiest way to grok how these operations are implemented is to implement them yourself. So I &lt;a href=&#34;https://github.com/dborzov/XLtrie&#34;&gt;did&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here is our toy case. With movie and tv show titles such as X-files, X-men and American History X, we have a trope of X standing for something misterious (and heavily implied to be hip). How often are movies with such titles released? What was the first X-movie released since, say 1975?&lt;/p&gt;

&lt;p&gt;To find out, let us build the X-fast trie index for such X-titled movies by the year of release.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s consider years from 1950 + 64 = 2004 to be our M= 2^6 - 1=63 range.
Here is a plot of what all the M leaves and the color of parent nodes for each of the depth levels:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://localhost:1313/img/movies.png&#34; alt=&#34;Img&#34; /&gt;
&lt;/p&gt;

&lt;p&gt;We have total of &lt;code&gt;x&lt;/code&gt; levels, where x comes from $M &amp;lt; 2^x -1$. That means we have got &lt;code&gt;x&lt;/code&gt; hash functions where we store keys of the &amp;ldquo;black&amp;rdquo;-marked nodes. Root level 0 contains only one node, in our case a blue/black one (it is always black as long as there is a single value within &lt;code&gt;{n}&lt;/code&gt;). The second lower level, 1, contains two nodes and so on.&lt;/p&gt;

&lt;p&gt;In order to look up the predecessor movie for 1975 we start the binary search for the specific level where the nodes turn white by looking up the corresponding node values within the parent nodes. We find out that the level is 3. Then we traverse down along the left side and find the corresponding predecessor movie: Lolly-Maddonna XXXX (1973).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now add another movie, say, &amp;ldquo;Not a Real Movie X (1975)&amp;rdquo;. That would mean we need to go through all the parent nodes and make sure they are added to the corresponding level hash functions.&lt;/p&gt;

&lt;h4 id=&#34;back-to-earth-practical-examples:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;Back to Earth (practical examples)&lt;/h4&gt;

&lt;p&gt;Let&amp;rsquo;s come up with some practical examples of where X-fast trie can be useful:&lt;/p&gt;

&lt;p&gt;Imagine you are developing a flight search website. You need to build a tailored search index that is really good at one task: for the given date and search criteria returns the list of the next flights. How is it better to approach designing this?&lt;/p&gt;

&lt;p&gt;This is an example of encountering predecessor/successor search problem in practice. Predecessor/successor search (or predecessor search for &amp;lsquo;short&amp;rsquo;) stands for cases when we have some dictionary (&lt;em&gt;in our case, the flight timetable&lt;/em&gt;) with its keys (&lt;em&gt;departure times&lt;/em&gt;) making up a subset of some ordered sequence (&lt;em&gt;like all minutes in the time range of interest or something&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;We want to design a system that for a given query element of that sequence (such as &lt;em&gt;our preferable flying date and time&lt;/em&gt;) would return the closest next subsequest element that is a key of our dictionary(&lt;em&gt;next flight from our query time&lt;/em&gt;):&lt;/p&gt;

&lt;p&gt;For the flight search website that would include the two following typical database tasks:&lt;/p&gt;

&lt;p&gt;I have been reading up about  recently and decided to write up some notes  and also to make a simple python implementation to go along with it.&lt;/p&gt;

&lt;p&gt;Obviously, it is incredibly inefficient to just store them as a list and go through the list each time. We need some kind of a search tree.&lt;/p&gt;

&lt;p&gt;Times of planes leaving (for example, in minutes) make up a subset of all the possible times (all minutes in the span of the existence of that specific airport). thus we can store them as a set of natural numbers  in a certain range of integers.&lt;/p&gt;

&lt;p&gt;So with that representation we can use the Direct Access Table. That is, make up a binary table of size  |S|.&lt;/p&gt;

&lt;p&gt;What are some ways to tackle the predecessor/successor problem? Naively we can just move along up the Direct Access Table until we stumble upon the next record. The worst case scenario here would be just going through the whole empty table, &lt;strong&gt;O(m)&lt;/strong&gt; .&lt;/p&gt;

&lt;p&gt;One improvement is to store pointers for predecessor/successor elements at each element. It does improve the predecessor/successor retrieval to just &lt;strong&gt;O(1)&lt;/strong&gt; . However, we have a inserting or deleting elements becomes a costly procedure as we have to reassign every nearby value, &lt;strong&gt;O(m)&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Here is the proposition. We build an ordered binary tree atop the m elements and mark every node that is a parent of the checked element. With each layer having two times less elements we only increased the total size of the array by two.&lt;/p&gt;

&lt;h4 id=&#34;see-also:58b12276bf0ae383f71846d6c29edb1d&#34;&gt;See also&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/X-fast_trie&#34;&gt;X-fast tries&lt;/a&gt; in Wikipedia&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Floating-point considered harmful</title>
      <link>http://localhost:1313/posts/floating-point/</link>
      <pubDate>Mon, 20 May 2013 08:36:54 -0700</pubDate>
      
      <guid>http://localhost:1313/posts/floating-point/</guid>
      <description>

&lt;h1 id=&#34;floating-point-considered-harmful:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;Floating-point considered harmful&lt;/h1&gt;

&lt;h3 id=&#34;abstract-modern-datatypes-for-quantities-such-as-length-time-or-a-number-should-employ-ideas-from-the-functional-programming-keep-track-of-when-the-rounding-errors-arise-support-defining-with-functions-represent-results-appropriately-to-the-context-flaky-an-open-source-framework-wants-to-make-things-right:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;&lt;em&gt;Abstract:&lt;/em&gt; Modern datatypes for quantities (such as length, time or a number) should employ ideas from the functional programming: keep track of when the rounding errors arise,  support defining with functions, represent results appropriately to the context. Flaky, an open source framework, wants to make things right.&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Floating_point&#34;&gt;Floating point datatype&lt;/a&gt; is the de-facto standard for real world quantities. Whether it is your GPS coordinates or sizes of the bridge nearby (likely designed in AutoCAD), this datatype lies in the foundation of every system. Since its introduction in the dawn of computing, floating point was accepted almost universally.&lt;/p&gt;

&lt;p&gt;Advantages such as scalability, resilience and ease of use make floating point the datatype of choice again and again. However, it is also fragile and prone to errors. This limitations are well known, of course, and could be minimized with appropriate  expertise and focus.&lt;/p&gt;

&lt;p&gt;And yet I believe that we, as an industry, could do better. Number representation based on the ideas of functional programming minimizes flaws characteristic to the floating point datatypes. And it can be made as resilient and scalable as the floating point. In this article, I outline why I decided to write Flaky, an open source library that attempts to implement such concepts.&lt;/p&gt;

&lt;p&gt;In the first section we will glance at illustrating cases of when floating point breaks and try to understand what flaws should be addressed. We then look at other initiatives in this space. Finally, I introduce the design that I came up with for Flaky.&lt;/p&gt;

&lt;h2 id=&#34;when-floating-point-fails:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;When floating point fails&lt;/h2&gt;

&lt;p&gt;Let us consider illustrative cases of when floating point representation leads to dramatically wrong answers.&lt;/p&gt;

&lt;h4 id=&#34;accumulating-errors:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;Accumulating errors&lt;/h4&gt;

&lt;p&gt;Well, this one is obvious. When the number cannot be represented exactly, it has to be rounded up. These rounding errors can accumulate and can lead to silly results.&lt;/p&gt;

&lt;p&gt;Let us, for example, take the square root of a number several times, and then try to reproduce the original value with the reversal operation (that is, taking squares)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# price.py listing, a Python script
import math
INITIAL_VALUE=1.9934545345

def reversable_iterations(iteration_number):
    test_floating = INITIAL_VALUE
    for i in range(iteration_number):
        test_floating = math.sqrt(test_floating)
    for i in range(iteration_number):
        test_floating = test_floating**2
    return &#39;with &#39;+str(iteration_number)+&#39; iterations, we get &#39;+str(test_floating)

print &#39;The intial value is &#39;,INITIAL_VALUE
print reversable_iterations(1)
print reversable_iterations(10)
print reversable_iterations(20)
print reversable_iterations(40)
print reversable_iterations(50)
print reversable_iterations(60)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This yields:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;The intial value is  1.9934545345
with 1 iterations, we get 1.9934545345
with 10 iterations, we get 1.9934545345
with 20 iterations, we get 1.99345453444
with 40 iterations, we get 1.99311204568
with 50 iterations, we get 1.64872126455
with 60 iterations, we get 1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That the end result breaks is hardly a  surprise. Moreover, a similar effect could be achieved for any number representation datatype. Just from the general principles, if the size  of the &lt;a href=&#34;http://en.wikipedia.org/wiki/Kolmogorov_complexity&#34;&gt;Kolmogorov complexity&lt;/a&gt; of a number is larger than the memory allocated for the datatype, these types of errors cannot be ruled out.&lt;/p&gt;

&lt;p&gt;What I wanted to emphasize here instead is the total equanimity of the floating type. It is very hard to understand what is going on at various stages. In my opinion, this is an incredible engineering design flaw.&lt;/p&gt;

&lt;p&gt;To see what I mean, let us figure out why the error is of order of 10% for 50 iterations, but converges to a wrong answer at 60. To do this we have to know how the number is represented internally, look up the default  &lt;a href=&#34;https://en.wikipedia.org/wiki/Significand&#34;&gt;mantissa/significand&lt;/a&gt; size for the programming language of our choice and make the estimation calculation on a piece of paper.&lt;/p&gt;

&lt;p&gt;The lack of the uncertainty estimation defeats the whole purpose of any computation.&lt;/p&gt;

&lt;h4 id=&#34;the-quadratic-equation:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;The quadratic equation&lt;/h4&gt;

&lt;p&gt;Even writing a program that solves the quadratic equation
for arbitrary constant values is a serious task.
For example, let us consider the following equation
[
&lt;img src=&#34;./img/quadratic.gif&#34; alt=&#34;Img&#34; /&gt;

]
Note that there is no constant term and thus one solution is simply zero. However, the naive solution with the quadratic formula fails to reflect this. Here is the first Google result for &amp;ldquo;quadratic equation solver&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;[
&lt;img src=&#34;./img/QuadraticEquation.png&#34; alt=&#34;Img&#34; /&gt;

]
For the general case implementation, we must treat each marginal case separately. First, if the constant term is zero, then if the quadratic term is absent, and so on, one by one.&lt;/p&gt;

&lt;p&gt;Quadratic equation is the simplest case of the numerical problem imaginable. Yet even here we see that one needs to manually implement basic calculus logic behind the known solution.&lt;/p&gt;

&lt;h4 id=&#34;scaling-does-not-match-the-problem:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;Scaling does not match the problem&lt;/h4&gt;

&lt;p&gt;Let us once again consider the quadratic equation, but this time in terms of the new variable we introduce
[
y = \frac{\textrm{exp}(x)}{1 + \textrm{exp}(x)}
]
The quadratic equation in terms of y looks as follows
[
a \textrm{ log}^2 (\frac{y}{1-y}) + b \textrm{ log} (\frac{y}{1-y}) + c = 0
]
Here is what the plot of the definition of the y function looks like
[
&lt;img src=&#34;img/softThreshold.png&#34; alt=&#34;Img&#34; /&gt;

]
The variable y &amp;ldquo;maps&amp;rdquo; the whole x range to its (0,1) range. This function is also known as the soft threshold.&lt;/p&gt;

&lt;p&gt;Attempting to solve this problem numerically in terms of y should be quite challenging. The number representation for y means that all the &amp;ldquo;graining&amp;rdquo; for sufficiently large x values (say, x&amp;gt;5) becomes too rude.&lt;/p&gt;

&lt;p&gt;That is, the number representation for the floating point
[
\underbrace{\text{integer}}_{\text{mantissa}} \cdot \text{base}^\text{exponent}
] offers the scale that is not appropriate for this problem. The solutions for large x should fail spectacularly. Interestingly, the solutions with the y going to the zero limit (x going negative, for example, x&amp;lt;-5) will be a little more resilient. The lack of the constant term (1. for large x) means that the base of the exponent will scale down gracefully.&lt;/p&gt;

&lt;p&gt;How does this issue work for the (relatively) real world problems? Let me share my personal experience. In our research study on &lt;a href=&#34;http://prl.aps.org/abstract/PRL/v110/i14/e145301&#34;&gt;the physics of ultracold gases in 2D&lt;/a&gt; we derived a complex equation we ended up solving numerically. The solution function was diverging logarithmically in the limit in which we were interested&lt;/p&gt;

&lt;p&gt;[ f(x) =  \textrm{Log}( x )^{w} + \text{ non-diverging terms }, x \rightarrow 0 ]&lt;/p&gt;

&lt;p&gt;However, it turned out practically impossible to learn the order of the divergence w from this numerical solution. The floating point representation meant that the log of the number is represented inefficiently for the problem.&lt;/p&gt;

&lt;p&gt;The solution was to introduce the new variable
[
z = -\textrm{Log}( x )
]
and express the whole problem and the solution in terms of z.&lt;/p&gt;

&lt;p&gt;Matching the number representation scale to the problem in the general case, is of course, impossible. It depends on the interpretation of the problem , what we are actually interested in.&lt;/p&gt;

&lt;p&gt;However, it would have been helpful if it was possible to tweak the scaling used without too much hassle.&lt;/p&gt;

&lt;h4 id=&#34;summary:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;Summary&lt;/h4&gt;

&lt;p&gt;Here is how the new quantity datatypes could be better:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We saw in the example of accumulating errors that every operation performed with the number should be traceable. Errors and uncertainties should be recorded from each operation and reported when needed.&lt;/li&gt;
&lt;li&gt;With the quadratic equation solver it is obvious that tracing analytic expressions used for computations allow for automatic implementation of the marginal cases and can save the developer a lot of time.&lt;/li&gt;
&lt;li&gt;Datatype representation scaling should match the problem at hand and not be fixed. Tools must exist to do this with ease.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;doing-things-right:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;Doing things right&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;An infinite number of mathematicians walk into a bar. The first orders a beer. The second orders half a beer. The third orders a quarter of a beer. Before the next one can order, the bartender says, “You’re all assholes,” and pours two beers. &lt;a href=&#34;http://www.komplexify.com/math/jokes/MathWalksIntoABar3.html&#34;&gt;TE&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we let us discuss the solutions that can fix these issues.&lt;/p&gt;

&lt;h4 id=&#34;what-is-out-there:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;What is out there.&lt;/h4&gt;

&lt;p&gt;Apparently, the best way to approach the problem is to use the functional programming concepts. To retain the analytical expression used for the value definition, at least to some limit, and to have tools to change it when needed.&lt;/p&gt;

&lt;p&gt;A classic case where the functional number representation was implemented is the language behind Wolfram Mathematica.
Too bad that for the non-technical reasons it is apparently destined to go into obscurity and not fulfill its full potential.&lt;/p&gt;

&lt;p&gt;Another example when things seem to be done right is the &lt;a href=&#34;http://sympy.org/en/index.html&#34;&gt;SymPy&lt;/a&gt;, a Python package for symbolic computations. Functional number representation is very solid. It is important to note, however, that the goal of the project is to make tools for symbolic calculations, not to create a viable alternative to the floating point.&lt;/p&gt;

&lt;h4 id=&#34;why-not-flaky:8b3822e7aabbd2c466e5591b1aa4f6cb&#34;&gt;Why not flaky.&lt;/h4&gt;

&lt;p&gt;So we saw how to make things better and why we should. These reasons compelled me start Flaky, the open-source project for quantity datatype based on the concepts of functional programming.&lt;/p&gt;

&lt;p&gt;Numbers are represented as operations to the other numbers. Together they can make up long layers (or flakes). Simplifying occurs whenever possible.&lt;/p&gt;

&lt;p&gt;[
(\textrm{frac},4,(\textrm{pow}, 5,(\textrm{frac},1,2))) = \frac{4}{\sqrt{5}}
]&lt;/p&gt;

&lt;p&gt;The size parameter defines when the datatype length is judged to be too long, then the rounding up occurs. There is a logging method to keep track of it. There is also the uncertainty estimation for margins of confidence.&lt;/p&gt;

&lt;p&gt;One may choose the specific representation of the number. Matching, rounding and scaling happens seamlessly.&lt;/p&gt;

&lt;p&gt;Flaky is written in the &lt;a href=&#34;http://www.golang.org&#34;&gt;Go programming language&lt;/a&gt;. The repository is available on &lt;a href=&#34;https://github.com/dborzov/FlakyPastry&#34;&gt;Github&lt;/a&gt; (or will be soon :)) .&lt;/p&gt;

&lt;p&gt;A discussion of this post is available on &lt;a href=&#34;https://news.ycombinator.com/item?id=5731366&#34;&gt;Hacker News&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>